{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Writting-custom-layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOoswx721IWINaJX8kk4V8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/menon92/DL-Sneak-Peek/blob/master/Writting_custom_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iaLVt0YE0H3",
        "outputId": "6e3501a0-a31e-43c9-9331-331d121ebdea"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJZbwJ3DFyaw"
      },
      "source": [
        "\n",
        "## এই নোটবুকে আমরা যে বিষয় নিয়ে কথা বলব\n",
        "- লেয়ার কি \n",
        "- লেয়ার ক্লাস এবং কাস্টম লেয়ার\n",
        "- কাস্টম লেয়ার লেয়ার ব্যবহার করে সেলসিয়ার টু ফারেনহাইট মডেল ট্রেনিং করা\n",
        "- `self.add_weight` মেথড কখন ব্যবহার করব\n",
        "- `build` কখন ইমপ্লিমেন্ট করতে হবে\n",
        "- কাস্টম লেয়ার লেয়ার ব্যবহার করে `MNIST` ডিজিট ক্লাসিফাই করা"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDHGds-VN1-i"
      },
      "source": [
        "## লেয়ার কি ?\n",
        "লেয়ার হল যেকোনো নিউরাল নেটওয়ার্ক ডিজাইন করার বিল্ডিং ব্লক । [VGG](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png), [ResNet](https://www.researchgate.net/profile/Weizhen-Fang-2/publication/335213445/figure/fig2/AS:793426240995328@1566178965482/Structure-of-the-ResNet-50-used-for-reservoir-recognition.jpg) এই নেটওয়ার্ক গুলো আসলে বিভিন্ন লেয়ার এর সমন্বয়ে গঠিত । নেটওয়ার্ক ডিজাইনের সুবিধার্থে টেন্সরফ্লো যে লেয়ার গুল খুব বেশি ব্যবহার হয় সেগুলো আগে থেকেই ইমপ্লিমেন্ট করে রেখেছে । যেমন : [Dense](https://keras.io/api/layers/core_layers/dense/), [Conv1D](https://keras.io/api/layers/convolution_layers/convolution1d), [Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d). এই রকম আরও [অনেক](https://keras.io/api/layers/) প্রয়োজনীয় লেয়ার ইমপ্লিমেন্ট করাই আছে । আপনি আপানর প্রয়োজন অনুসারে এইগুলো ব্যবহার করতে পারেন । \n",
        "\n",
        "এই সবগুলো লেয়ারের মুল কাজ এর কাছে আসা ইনপুট কে ট্রান্সফরম করা এবং এই ট্রান্সফরমড অউতপুত রিটার্ন করা । ডাটার এই ট্রান্সফরমেশন একেক লেয়ার একেক ভাবে হয়ে থেকে । \n",
        "\n",
        "অনেক সময় যদি আপনার এমন দরকার হয় যে আপনি আপনার মত করে ইনপুট ডাটার ট্রান্সফরমাশন করতে চান তাহলে কাস্টম লেয়ার ইমপ্লিমেন্ট করতে পারেন । \n",
        "\n",
        "লেয়ার ক্লাস গুল ওয়েট ভেরিয়াব, বায়াস ভেরিয়াবল এবং কিছু কম্পুউটেসনের সমন্বয়ে গঠিত হয় । মনে করে আমরা একটা কাস্টম লেয়র লিখতে চাই যেটা দেখতে নিচের মত । \n",
        "\n",
        "```\n",
        "y = W*x + b\n",
        "```\n",
        "যেখানে,\n",
        "```\n",
        "লেয়ার ওয়েট ভেরিয়েবল\n",
        "লেয়ার বায়াস ভেরিয়েবল \n",
        "লেয়ারের ইনপুট\n",
        "লেয়ারের অউতপুট\n",
        "```\n",
        "ওয়েট, বায়াস কে লেয়ারের স্টেট ভেরিয়েবলও বলা হয়ে থাকে । এই রকম নাম দেয়ার করন আপনি যখন এই লেয়ার কে নেটওয়ার্ক ডিজাইন করার সময় ব্যবহার করবেন এবং আপনার নেটওয়ার্ক কে কোন ডাটার উপর ট্রেনিং করবেন তখন প্রতিবার নেটওয়ার্ক [ব্যাক-প্রপ্রাগ্রেশনের](https://en.wikipedia.org/wiki/Backpropagation) সময় এই সব স্টেট ভেরিয়েব কে আপডেট করে । অর্থাৎ আপনার পুরার নেটওয়ার্ক এর স্টেট পরিবর্তন হয় । "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRnYh6owN1SM"
      },
      "source": [
        "## লেয়ার ক্লাস এবং কাস্টম লেয়ার\n",
        "\n",
        "কাস্টম লেয়ার তৈরি করর জন্য আমাদের কয়েকটা জিনিস লাগবে, \n",
        "\n",
        "- Layer ক্লাস ইনহেরিট করা \n",
        "- __init__() লেয়ারের প্রয়োজনীয় ভেরিয়াবল ইনিসিয়ালাইজ করা\n",
        "- call() ইনপুট ডাটা ট্রান্সফরমেসন লজিক ইমপ্লিমেন্ট করা\n",
        "- build() যদি আমাদের এমন কোন ভেরিয়েবল ইনিসিয়ালাইজ করর দরকার হয় সেটা ইনপুট সেইপ আগে থেকে জানি না । সেই ধরনের ভেরিয়েবল আমাদের কে build এর মাঝে ইনিসিয়ালাজ করতে হবে \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74HebF-yFc8a"
      },
      "source": [
        "class Linear(keras.layers.Layer): # লেয়ার ক্লাস কে ইনহেরিট করি\n",
        "    '''Custom layer that implements y = wx + b\n",
        "    '''\n",
        "    def __init__(self, units=8, input_dim=8):\n",
        "        # মুল Layer ক্লাস কে ইনিসিলাইজ করি\n",
        "        super(Linear, self).__init__()\n",
        "\n",
        "        # tf.random_normal_initializer() ফাংশন কোন ডিরেক্ট রেন্ডম নাম্বার জেনারেট করে না \n",
        "        # শুধু রেন্ডম নাম্বার জেনারেট করার জন্য ইনিসিয়ালাইজ হয়ে থাকে, এটা কে যেকোনো শেপ দিয়ে কল করলে \n",
        "        # এটা সেই শেপের রেন্ডম নাম্বার জেনারেট করে দেয়। \n",
        "        w_init = tf.random_normal_initializer()\n",
        "        print(f\"w_init: {w_init}\")\n",
        "\n",
        "        # আমরা এখানে `w_init` ব্যবহার করে w কে রেন্ডম নাম্বার দিয়ে ইনিসিয়ালাইজ করি । \n",
        "        self.w = tf.Variable(\n",
        "            # আমরা সেপ ডাটা টাইপ দিয়ে দিলাম\n",
        "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
        "            # ব্যাক-প্রপাগ্রেসনের সময় w এর মান পরিবর্তন হবে কি না সেটা বলে দিলাম। অনেক সময় ট্রান্সফার লার্নিং \n",
        "            # করার সময় দরকার হয় যে, আমরা আগের ট্রেনিং করা ওয়েট কে পরিবর্তন করব না । তখন আমরা \n",
        "            # এটা কে False করে দিলেই ব্যাক-প্রপাগ্রেসনের সময় w পরিবর্তন হবে না ।\n",
        "            trainable=True\n",
        "        )\n",
        "        print(f'self.w: {self.w}')\n",
        "        # ওয়েট ভেরিয়েবল এর মত একই ভাবে আমরা বায়াস ভেরিয়েবল কে ইনিসিয়ালিজ করি\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=b_init(shape=(units,), dtype=\"float32\"),\n",
        "            trainable=True\n",
        "        )\n",
        "        print(f'b_init: {b_init}')\n",
        "        print(f'self.b: {self.b}')\n",
        "\n",
        "    def call(self, x):\n",
        "        # w*x + b  ট্রান্সফরমেসন লজিক ইমপ্লিমেন্ট করি\n",
        "        return tf.matmul(x, self.w) + self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTPsD0Dg6ecD"
      },
      "source": [
        "এখন আমরা আমাদের বানানো কাস্টম লেয়ার কে স্যাম্পল ডাটা দিয়ে টেস্ট করে দেখব। "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmpPWXptFdiI",
        "outputId": "11129a11-a951-4446-a768-feea4e0c5e25"
      },
      "source": [
        "# 1x4 সাইজের ইনপুট ডিফাইন করি । এটা কে আমরা লেয়ারে ইনপুট ডাটা হিসাবে ব্যবহার করব\n",
        "# এখানে আমাদের ১ টা ডাটা আছে যার ডাইমেসন ৪\n",
        "x = tf.ones((1, 4))\n",
        "\n",
        "# লেয়ার ইনিসিয়ালাইজ করি \n",
        "linear_layer = Linear(\n",
        "    # এই লেয়ারে ডাটা উপর ট্রান্সফরমেসন অ্যাপ্লাই হওয়ার পরে \n",
        "    # যে ডাটা আমরা পাব তার শেষ ডাইমেসন কত চাচ্ছি সেটা ডিফাইন করে দিলাম\n",
        "    # units = 2 মানের লাস্ট ডাইমেসন হবে 2, 16 দিলে 16 হবে \n",
        "    units=2,\n",
        "    # যেহেতু আমাদের ডাটার ডাইমেনসন 4 তাই আমরা input_dim = 4 সেট করে দিলাম ।\n",
        "    # অন্য ডাইম্যানসন দিলে এরর হবে\n",
        "    input_dim=4\n",
        ")\n",
        "\n",
        "# আমাদের ডাটা x কে আমাদের বানানো লেয়ারের মাঝে দিয়ে পাস করি\n",
        "y = linear_layer(x)\n",
        "\n",
        "# লেয়ার ডাটা x কে ট্রান্সফরম করার পরের অউতপুট প্রিন্ট করি\n",
        "print(f\"\\ny :{y}\")\n",
        "print(f\"shape: {y.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w_init: <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7f1e295a7c50>\n",
            "self.w: <tf.Variable 'Variable:0' shape=(4, 2) dtype=float32, numpy=\n",
            "array([[-0.02637166,  0.06013067],\n",
            "       [ 0.05447754,  0.05503648],\n",
            "       [-0.01913537, -0.01881706],\n",
            "       [-0.07917801,  0.01136541]], dtype=float32)>\n",
            "b_init: <tensorflow.python.ops.init_ops_v2.Zeros object at 0x7f1e295a7a90>\n",
            "self.b: <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n",
            "\n",
            "y :[[-0.07020751  0.10771549]]\n",
            "shape: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFFjAFggosvC"
      },
      "source": [
        "শেপের মান আমরা পাইলাম shape: (1, 2) অর্থাৎ লাস্ট ডাইমেনসন 2 কারণ আমরা ইউনিট = 2 দিয়েছিলাম\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q4cmskyicH7"
      },
      "source": [
        "## কাস্টম লেয়ার লেয়ার ব্যবহার করে সেলসিয়ার টু ফারেনহাইট মডেল ট্রেনিং করা\n",
        "এখন আমাদের বানানো এই কাস্টম লেয়ার ব্যবহার করে কোন তাপমাত্রা সেলসিয়াস এ দেয়া থাকলে সেটা ফারেনহাইটে কনভার্ট করতে পারি কি না সেটা চেক করে দেখব। সেলসিয়াস থেকে ফারেনহাইটে কনভার্ট করার সূত্র এই রকম,  \n",
        "\n",
        "# $$ f = c \\times 1.8 + 32 $$\n",
        "\n",
        "এখানে `self.w = 1.8, self.b = 32` হিসাবে চিন্তা করতে পারি । নিচে আমরা দেখব আমাদের কাস্টম লেয়ার এই মান গুলো শিখতে পারে কি না । \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTdAbrGABbc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd3c6d3-352e-4a5c-ee36-19fffa78b552"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "    def __init__(self, units=8, input_dim=8):\n",
        "        super(Linear, self).__init__()\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
        "            trainable=True\n",
        "        )\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=b_init(shape=(units,), dtype=\"float32\"),\n",
        "            trainable=True\n",
        "        )\n",
        "    def call(self, x):\n",
        "        return tf.matmul(x, self.w) + self.b\n",
        "\n",
        "# সেলসিয়াস এ তাপমাত্রা\n",
        "X = np.array([[-40], [-10],  [0],  [8], [15], [22],  [38]],  dtype='float32')\n",
        "# ফারেনহাইট এ তাপমাত্রা \n",
        "y = np.array([[-40],  [14], [32], [46], [59], [72], [100]],  dtype='float32')\n",
        "\n",
        "# Loss function\n",
        "def loss(real_y, pred_y):\n",
        "    return tf.abs(real_y - pred_y)\n",
        "\n",
        "epochs = 501\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "# লেয়ার ইনিসিয়ালাইজ করি\n",
        "linear_layer = Linear(units=1, input_dim=1)\n",
        "\n",
        "def train_step(real_x, real_y):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # take transformed output from layer\n",
        "        pred_y = linear_layer(real_x)\n",
        "        # calculate loss\n",
        "        reg_loss = loss(real_y, pred_y)\n",
        "    # Calculate gradients with respect to reg_loss\n",
        "    grads = tape.gradient(reg_loss, linear_layer.trainable_weights)\n",
        "    # Update trainable variables\n",
        "    optimizer.apply_gradients(zip(grads, linear_layer.trainable_weights))\n",
        "\n",
        "    return reg_loss\n",
        "\n",
        "# training the layer up to given epochs\n",
        "for e in range(epochs):\n",
        "    reg_loss = train_step(X, y)\n",
        "    if e % 100 == 0:\n",
        "        # show loss, status of state variable w, b\n",
        "        updated_w, updated_b = linear_layer.trainable_weights\n",
        "        print(f'Epoch: {e} loss: {tf.reduce_sum(reg_loss).numpy():.3f}')\n",
        "        print(\n",
        "            f'Updated w: {np.squeeze(updated_w.numpy()):.3f} '\n",
        "            f'updated b: {np.squeeze(updated_b.numpy()):.3f}'\n",
        "        )\n",
        "        print('-' * 40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 loss: 361.588\n",
            "Updated w: 0.112 updated b: 0.100\n",
            "----------------------------------------\n",
            "Epoch: 100 loss: 134.785\n",
            "Updated w: 2.362 updated b: 10.119\n",
            "----------------------------------------\n",
            "Epoch: 200 loss: 74.673\n",
            "Updated w: 2.113 updated b: 20.014\n",
            "----------------------------------------\n",
            "Epoch: 300 loss: 14.678\n",
            "Updated w: 1.863 updated b: 29.902\n",
            "----------------------------------------\n",
            "Epoch: 400 loss: 1.267\n",
            "Updated w: 1.815 updated b: 31.998\n",
            "----------------------------------------\n",
            "Epoch: 500 loss: 1.572\n",
            "Updated w: 1.788 updated b: 31.993\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd8xuKU9CbQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d067a500-6e1e-4dee-b7c2-0f139befe8ad"
      },
      "source": [
        "# ট্রেনিং শেষ এখন আমরা ডাটা দিয়ে টেস্ট করে দেখি আমদের লেয়ার কিছু শিখতে পারল কি না \n",
        "prediction = linear_layer(X)\n",
        "for pred, target in zip(prediction, y):\n",
        "    print(f\"Target fahrenheit: {target} predicted: {pred}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target fahrenheit: [-40.] predicted: [-39.536186]\n",
            "Target fahrenheit: [14.] predicted: [14.111048]\n",
            "Target fahrenheit: [32.] predicted: [31.99346]\n",
            "Target fahrenheit: [46.] predicted: [46.29939]\n",
            "Target fahrenheit: [59.] predicted: [58.817078]\n",
            "Target fahrenheit: [72.] predicted: [71.33476]\n",
            "Target fahrenheit: [100.] predicted: [99.946625]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VbY9cnMqH6e"
      },
      "source": [
        "উপরে আমরা দেখতে পাচ্ছি যে মোটামুটি ঠিক ভাবেই সেলসিয়াস কে ফারেনহাইটে পরিবর্তন করতে পারছে । আমরা এই লেয়ার কে `[-40], [-10],  [0],  [8], [15], [22],  [38]` এই কয়েকটা ডাটা দিয়ে ট্রেনিং করাইছি । এখন দেখি আমরা যদি এর বাহিরের কোন ডাটা ইনপুট দেয় তাহলে কি হয় । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mccKX2E1rJ3C",
        "outputId": "4617d0f2-ba13-4796-ab7a-9cd1dd17b1d5"
      },
      "source": [
        "celsius = 100\n",
        "print(\n",
        "    'Predicted:', np.squeeze(linear_layer(np.array([[celsius]], dtype='float32'))), \n",
        "    'actual:', 1.8*celsius + 32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: 210.81757 actual: 212.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZMvUpUxscUY"
      },
      "source": [
        "নতুন ডাটার জন্য লেয়ার কাছাকাছি মানই দিচ্ছে । এই রকম হওয়ার কারণ হল আমরা যদি ৫০০ ইপকে ট্রেনিং লগ দেখি সেটা কিছুটা এই রককম, \n",
        "\n",
        "```\n",
        "Epoch: 500 loss: 1.890\n",
        "Updated w: 1.795 updated b: 31.993\n",
        "```\n",
        "অর্থাৎ `w, b` এর মান যথাক্রম `1.795, 31.993` যেটা  `1.8, 32` এর কাছাকাছি । "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B0S_SAR96oN"
      },
      "source": [
        "\n",
        "## কখন এবং কেন build() ব্যবহার করব \n",
        "\n",
        "আমরা শুরুর দিকে বলেছিলাম যে build তখনি ইমপ্লিমেন্ট করতে হবে যদি আমরা আগে থেকে লেয়াররের ইনপুট কি হবে সেটা বলে দিতে না পারি । আমাদের যদি পুরা নেটওয়ার্কের জন্য কেবল মাত্র ১ তা লেয়ার ব্যবহার করি তাহলে build এর দরকার নাই. \n",
        "\n",
        "কিন্তু রিয়েল নেটওয়ার্ক গুল অনেক লেয়ার নিয়ে গঠিত হয় কিছুটা এই রকম\n",
        "\n",
        "```python\n",
        "# l1 এর input_dim আমরা দিতে পারতেছি\n",
        "l1 = Linear(units=8, input_dim=100)\n",
        "# কিন্তু l2 এর input_dim নির্ভর করতেছে l1 এর অউতপুটের উপর\n",
        "l2 = Linear(units=16)(l1)\n",
        "l3 = Linear(units=16)(l2)\n",
        "# একই ভাবে l4 এর input_dim নির্ভর করতেছে l3 এর উপর\n",
        "l4 = Linear(units=32)(l3)\n",
        "```\n",
        "\n",
        "উপরের বিষয়টা যদি আমরা হ্যান্ডলে করতে চাই তাহলে আমাদের কে `build` ইমপ্লিমেন্ট করতে হবে ।  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7rAN06OFdpR"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(Linear, self).__init__()\n",
        "        # এখানে আমরা input_shape দিলাম না । \n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # w_init = tf.random_normal_initializer()\n",
        "        # self.w = tf.Variable(\n",
        "        #     initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
        "        #     trainable=True\n",
        "        # )\n",
        "        # উপরে যেভাবে ওয়েট ইনিসিয়ালাইজ করা হয়েছে সেটা ১ লাইনে করতে চাইলে আমরা \n",
        "        # `keras.layers.Layer` এর  self.add_weight মেথড ব্যবহার করতে পারি  \n",
        "        self.w = self.add_weight(\n",
        "            # ইনপুট ডাটার ডাইম্যানসনের উপর নির্ভর করে ইনপুট সেপ নিয়ে নিলাম\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.matmul(inputs, self.w) + self.b\n",
        "        # এই লেয়ার আমরা MNIST ডাটাসেটের উপর ব্যবহার করব, যেহেতু এই ডাটা \n",
        "        # নিনিয়ার ভাবে ক্লাসিফাই করা যায় না এই জন্য আমরা লেয়ারে নন-লিনিয়ারিটি\n",
        "        # অ্যাড করলাম relu মেথডের মাধ্যমে \n",
        "        return tf.nn.relu(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14sFJS-ZyHtk",
        "outputId": "a7123114-9329-44cb-ba5f-d3faba80e7bf"
      },
      "source": [
        "# কিছু স্যাম্পল ডাটা তৈরি করে ৩ লেয়েয়ার মধ্যে দিয়ে ডাটা \n",
        "# পার করে দেখি কেমন অউতপুট দেয়\n",
        "\n",
        "inputs = tf.ones([1, 2])\n",
        "print('Sample input:', inputs)\n",
        "\n",
        "l1 = Linear(8)(inputs)\n",
        "l2 = Linear(8)(l1)\n",
        "l3 = Linear(4)(l2)\n",
        "\n",
        "print('Transformed output after passing it all the three layer:')\n",
        "print(l3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input: tf.Tensor([[1. 1.]], shape=(1, 2), dtype=float32)\n",
            "Transformed output after passing it all the three layer:\n",
            "tf.Tensor([[0.01034534 0.         0.01573105 0.02405714]], shape=(1, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXtYWJ0nGqKk"
      },
      "source": [
        "## কাস্টম লেয়ার লেয়ার ব্যবহার করে MNIST ডিজিট ক্লাসিফাই করা\n",
        "\n",
        "আমাদের লেয়ার এখন ইনপুট ডাইমেনসন বলে না দিলেও কাজ করে । এই জন্য আমরা একাধিক লেয়ার সমন্বয় করে `MNIST` ডাটাসেট ক্লাসিফাই করার নেটওয়ার্ক ডিজাইন করে ফেলি।  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UD1gsV30C3e"
      },
      "source": [
        "# একাধিক লেয়ার দিয়ে নেটওয়ার্ক ডিফাইন করি \n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(784,)),\n",
        "    Linear(64),\n",
        "    Linear(64),\n",
        "    Linear(10),\n",
        "])\n",
        "\n",
        "# optimizer.apply_gradients() এর মাধ্যমে আমদের কাস্টম লেয়ার গুলোর w, b উপডেট করবে\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "# নেটওয়ার্কের লস হিসাব করার জন্য ব্যবহার হবে\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# ট্রেনিং আকুরেসি ট্রাক করার কাজে এটা ব্যবহার হবে\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "# ভ্যালিডেসন আকুরেসি ট্রাক করার কাজে এটা ব্যবহার হবে\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# ইন্টারনেট থেকে MNIST ডাটা ডাউনলোড করি\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = np.reshape(x_train, (-1, 784))\n",
        "x_test = np.reshape(x_test, (-1, 784))\n",
        "\n",
        "# spilt data into train, valication\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "# prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgZ_7KWX0O4Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rWUf4VC0O67",
        "outputId": "abff0be6-856e-4de0-8bb2-247884a113a3"
      },
      "source": [
        "import time\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # নেটওয়ার্ক থেকে অউতপুট নেই\n",
        "            logits = model(x_batch_train)\n",
        "            # নেটওয়ার্কের অউতপুট এবং অরিজিনাল লেবেল থেকে লস হিসাব করি\n",
        "            loss_value = loss_fn(y_batch_train, logits)\n",
        "        # লস এর সাপেক্ষে নেটওয়ার্ক এর সব w, b এর গ্র্যাডিয়েন্ট হিসাব করি\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        # এই গ্র্যাডিয়েন্ট এবং অপটিমাইজার ব্যবহার করে w, b এর মান উপডেট করি\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "        # update training metric.\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "    # store train metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    # reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # perform validatoin\n",
        "    # run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        val_logits = model(x_batch_val)\n",
        "        # update val metrics\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "    # store current validation accuracy\n",
        "    val_acc = val_acc_metric.result()\n",
        "    # reset the validation metrics at the end of each epoch\n",
        "    val_acc_metric.reset_states()\n",
        "\n",
        "    # display training, validaton summary\n",
        "    print(\n",
        "        f\"Epoch: {epoch+1} - train acc: {float(train_acc):.3f} - \"\n",
        "        f\"val acc: {float(val_acc):.4f} - time: {time.time() - start_time:.2f}s\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 - train acc: 0.357 - val acc: 0.5712 - time: 7.87s\n",
            "Epoch: 2 - train acc: 0.645 - val acc: 0.6710 - time: 7.77s\n",
            "Epoch: 3 - train acc: 0.745 - val acc: 0.7687 - time: 7.87s\n",
            "Epoch: 4 - train acc: 0.774 - val acc: 0.7714 - time: 7.76s\n",
            "Epoch: 5 - train acc: 0.777 - val acc: 0.7740 - time: 7.74s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT9mzf0yFgGl"
      },
      "source": [
        "## Referance\n",
        "- [Custom layer keras](https://www.tensorflow.org/tutorials/customization/custom_layers)\n",
        "- [Guide to custom layer](https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n",
        "- [New layer creation using subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)"
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/menon92/DL-Sneak-Peek/blob/master/%E0%A6%9F%E0%A7%87%E0%A6%A8%E0%A7%8D%E0%A6%B8%E0%A6%B0%E0%A6%AB%E0%A7%8D%E0%A6%B2%E0%A7%8B_%E0%A7%A8_%E0%A7%A6_%E0%A6%93_%E0%A6%95%E0%A7%87%E0%A6%B0%E0%A6%BE%E0%A6%B8_%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%9A%E0%A6%BF%E0%A6%A4%E0%A6%BF_%E0%A6%AA%E0%A6%B0%E0%A7%8D%E0%A6%AC_%E0%A7%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMAchtYPhyTl"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version এই কমান্ড কেবলমাত্র colab এ কাজ করে লোকাল নোটবুকে কাজ করবে না । \n",
    "  # এই জন্য try except ব্যাবহার করা হয়েছে । \n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4bvCX76iN8N"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_A360iRiOss"
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8JnkDShic5K"
   },
   "source": [
    "### ডাটাসেট ডাউনলোড \n",
    "\n",
    "ডাটাসেট ডাউনলোড করার জন্য আমরা `tf.keras.utils.get_file` এই ফাংশন ব্যাবহার করব । এখানে আমরা ডাটাসেট url এবং কি নামের (`fname='flower_photos'`) ফোল্ডারে ডাউনলোড হয়ে জমা হবে সেটা বলে দিচ্ছি । এবং `flower_photos.tgz` যেহেতু একটা জিপ ফাইল তাই এটাকে আনজিপ করার জন্য আমরা `untar=True` দিয়ে দিব । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "M6ZML7WMiRNX",
    "outputId": "9b0dccef-b21d-41eb-985d-794cb0775cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 2s 0us/step\n",
      "Dataset directory: /root/.keras/datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "DATASET_URL = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "\n",
    "data_dir = tf.keras.utils.get_file(origin=DATASET_URL, fname='flower_photos', untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "print('Dataset directory:', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "_I_sFSCHijsm",
    "outputId": "16758d64-943b-4c26-d295-1b35ccf6ecdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`daisy     ` folder contain 633 flower images\n",
      "`dandelion ` folder contain 898 flower images\n",
      "`roses     ` folder contain 641 flower images\n",
      "`sunflowers` folder contain 699 flower images\n",
      "`tulips    ` folder contain 799 flower images\n"
     ]
    }
   ],
   "source": [
    "FLOWERS = ['daisy', 'dandelion', 'roses','sunflowers','tulips']\n",
    "for flower in FLOWERS:\n",
    "    total_flower = len(list(data_dir.glob(flower + \"/*.jpg\")))\n",
    "    print(\"`{:10s}` folder contain {} flower images\".format(flower, total_flower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfVugNFWlMgY"
   },
   "source": [
    "Keras এর ImageDataGenerator দিয়ে ডাটা পাইপলাইন লিখে ফেলি । যেহেতু আমি আগের পর্ব গুলোতে এইগুলো সম্পর্কে ডিটেইল বলেছি এই জন্য এখানে আমি আর এটা সম্পর্কে ব্যাখ্যা করব না । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "afztCLaZioGm",
    "outputId": "3ebf011c-d6dd-4de0-d451-31824527aa91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "\n",
    "# defins params\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "\n",
    "# define class names\n",
    "CLASS_NAMES = np.array(\n",
    "    [item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "\n",
    "# init image data generator object \n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(\n",
    "    directory=str(data_dir),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb', # one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". \n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    classes = list(CLASS_NAMES),\n",
    "    class_mode='categorical' # \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\".\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9so63M8mMjy"
   },
   "source": [
    "এখন আমরা tf.data দিয়ে পাইপলাইন লিখেফেলি"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQLbL105l6Ql"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # print(parts)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == CLASS_NAMES\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # ছোট ডাটাসেটের জন্য `ds = ds.cache(cache)` দরকার নাই । কিন্তু ডাটাসেট যদি \n",
    "    # অনেক বড় হয় তাহলে RAM এ সব ডাটা একসাথে ধরবে না । তখন আমাদের কে HDD \n",
    "    # এর সাহায্য নিতে হবে । \n",
    "    if cache:\n",
    "        # যদি ডাটা অনেক বড় হয় তাহলে তাহলে আমরা ডাটাকে মেমরিতে না রেখে \n",
    "        # আমরা যে cache=যে পাথ দিব সেখানে ডাটা ক্যাশ করে রাখবে । \n",
    "        # নিচে এটারও আমরা একটা উদাহরণ দেখব । \n",
    "        if isinstance(cache, str):\n",
    "            # HDD এ ডাটা ক্যাশ করে রাখবে । \n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            # RAM এ ডাটা ক্যাশ করে রাখবে \n",
    "            ds = ds.cache()\n",
    "\n",
    "    # ডাটা আমরা সাফল করে নিচ্ছি \n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    \n",
    "    # ডাটাসেট অসংখ্যবার রিপিট হবে সেটা বলে দিলাম \n",
    "    ds = ds.repeat()\n",
    "\n",
    "    # BATCH_SIZE অনুসারে আমারা ডাটা নিয়ে নিচ্ছি \n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # যখন মডেল একটা ব্যাচ ডাটার উপর ট্রেনিং হতে থাকবে তখন পরবর্তী ব্যাচ আগে থেকেই প্রস্তুত করে রাখব \n",
    "    # যাতে করে মডেলের যখন নতুন ব্যাচ ডাটা দরকার তখন এসে অপেক্ষে করা না লাগে । \n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = prepare_for_training(labeled_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXkIJ8YBjNnf"
   },
   "source": [
    "## সময় কোনটাতে কেমন লাগে সেটা দেখি\n",
    "\n",
    "এখানে আমরা দেখব কোনটাতে কেমন সময় লাগে । প্রথমে আমরা একটা ফাংশন লিখি যেটা আমাদের কে এই ডাটাসেটের উপর কোনটা কোনটা কেমন সময় লাগতেছে সেটা হিসাব করে দিবে । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTldmd4djOS0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "default_timeit_steps = 1000\n",
    "\n",
    "def timeit(ds, steps=default_timeit_steps):\n",
    "    start = time.time()\n",
    "    it = iter(ds)\n",
    "    for i in range(steps):\n",
    "        batch = next(it)\n",
    "        if i%10 == 0:\n",
    "            print('.',end='')\n",
    "    print()\n",
    "    end = time.time()\n",
    "\n",
    "    duration = end-start\n",
    "    print(\"{} batches: {} s\".format(steps, duration))\n",
    "    print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXBLStzejbZU"
   },
   "source": [
    "এখন আমরা উপরের দুইটা ডাটা জেনারেটরে মধ্যে সময় হিসাব করি । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "4nXiWFrNjXId",
    "outputId": "8d5fb14e-8a9f-43a4-d747-9cfb7df98868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 84.32222032546997 s\n",
      "379.49665 Images/s\n"
     ]
    }
   ],
   "source": [
    "# `keras.preprocessing`\n",
    "timeit(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "7CaJi8B4jh9_",
    "outputId": "5a6f886e-59a6-40b8-a950-42c189bff61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 12.434528350830078 s\n",
      "2573.47919 Images/s\n"
     ]
    }
   ],
   "source": [
    "# `tf.data`\n",
    "timeit(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciHs3FfDjoCi"
   },
   "source": [
    "এখানে আমরা দেখতে পাচ্ছি দুইটার মধ্যে কত পার্থক্য । কিন্তু আমাদের মেমরি যদি কম হয় তাহলে এটা আমরা করতে পারব না । \n",
    "\n",
    "একবার প্রসেস করা ডাটা আমরা `.cache` এর মাধ্যমে জমা করে রাখব । পরের বার যখন একই ডাটার জন্য রিকুয়েস্ট করবে তখন আগে দেখবে ডাটা টা ক্যাশ এ আছে কি না । যদি ক্যাশ এ থাকে তাহলে সেটা রিটার্ন করবে । যদি ক্যাশ এ না থাকে তাহলে ডাটা কে প্রসেস করে ক্যাশ জমা রাখবে । যাতে পরবর্তী সময়ে সেটা ব্যাবহার করা যায় । \n",
    "\n",
    "ক্যাশ ব্যাবহার না করে দেখি কেমন সময় লাগে । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "E04wibI2jqyP",
    "outputId": "626acc8b-8d07-413e-8000-b14f0839fdd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 58.00709366798401 s\n",
      "551.65667 Images/s\n"
     ]
    }
   ],
   "source": [
    "uncached_ds = prepare_for_training(labeled_ds, cache=False)\n",
    "timeit(uncached_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqJcqWAjjtc5"
   },
   "source": [
    "যদি ডাটাসেট মেমরি তে ফিট না করে তাহলে আমরা ক্যাশ ডাটা কে একটা ফাইলে রাইট করে রাখব । এটা RAM এর মত ফাস্ট না হলেও `keras.preprocessing` থেকে অনেক ফাস্ট হবে । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "9IOzYksUjxJ7",
    "outputId": "e91d8951-e2ad-434a-c0e7-c3f2b0742156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 37.12383055686951 s\n",
      "861.98001 Images/s\n"
     ]
    }
   ],
   "source": [
    "# create a caches directory\n",
    "!mkdir caches\n",
    "\n",
    "filecache_ds = prepare_for_training(labeled_ds, cache=\"caches/flowers.tfcache\")\n",
    "timeit(filecache_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9b2WDfrFj2EH"
   },
   "source": [
    "আমরা `ls` করলে `flowers.tfcache` ফাইল দেখতে পারব । আমাদের ডাটাসেট যত বড় হবে এই ফাইলের সাইজ তত বড় হতে থাকবে ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "K9AUGGVVj6fC",
    "outputId": "a16fa5ca-6bad-4c2b-c011-6e6a2b013ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1G\tcaches/\n",
      "****************************************\n",
      "total 2158220\n",
      "-rw-r--r-- 1 root root 2209769390 May 16 04:00 flowers.tfcache.data-00000-of-00001\n",
      "-rw-r--r-- 1 root root     239989 May 16 04:00 flowers.tfcache.index\n"
     ]
    }
   ],
   "source": [
    "!du -sh caches/\n",
    "print('*'*40)\n",
    "!ls -l caches/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QgxO98Thj7WY"
   },
   "source": [
    "- মুল লেখা <a href=\"https://www.tensorflow.org/tutorials/load_data/images\"> Image data loading </a>\n",
    "- <a href=\"https://youtu.be/kVEOCfBy9uY?list=PLQY2H8rRoyvzIuB8rZXs7pfyjiSUs8Vza\"> TF inut pipeline  </a>\n",
    "- <a href=\"https://medium.com/analytics-vidhya/tensorflow-2-0-tf-data-api-eaa9889186cc\"> TensorFlow 2.0: tf.data API</a>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOGvdJ9Sbb1/nn1p35dHsWc",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "টেন্সরফ্লো ২.০ ও কেরাস পরিচিতি পর্ব - ৭.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

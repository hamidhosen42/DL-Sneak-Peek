{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf2pip] *",
      "language": "python",
      "name": "conda-env-tf2pip-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "drive-into-tokenizer.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/menon92/DL-Sneak-Peek/blob/master/drive_into_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o17uEw8ZcRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27e9bdb2-f865-4bdf-b7cb-866bda7da031"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlRIKf7fZcRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [\n",
        "    \"হুমায়ূন আহমেদ ছিলেন একজন বাংলাদেশী ঔপন্যাসিক\",\n",
        "    \"তিনি বিংশ শতাব্দীর জনপ্রিয় বাঙালি কথাসাহিত্যিকদের মধ্যে অন্যতম\", \n",
        "    \"তাকে বাংলাদেশের স্বাধীনতা পরবর্তী অন্যতম শ্রেষ্ঠ লেখক বলে গণ্য করা হয়\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_LDuvCcZcR5",
        "colab_type": "text"
      },
      "source": [
        "`tokenizer` অবজেক্ট ইনিসিয়ালিজ করি । আমরা `,।-` এই তিনটা ক্যারেক্টার বাদ দিতে চাচ্ছি এই জন্য `filters=',।-'` দিয়ে দিয়েছি । এর ফলে যত জায়গায় সে এই ক্যারেক্টার পাবে সবগুলো কে ডিলিট করে দিবে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jiZgMCWZcR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=',।-')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWHLq0SmZcSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# টেক্সট এর উপর ভিত্তি করে `tokenizer` ইন্টারনাল ভেরিয়েবল আপডেট করা \n",
        "tokenizer.fit_on_texts(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7UPs9pwZcSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "4c823674-978f-4593-c33b-0ec2789ced35"
      },
      "source": [
        "# দেখি এই `tokenizer` আমাদের কি কি ফাংশন অফার করে \n",
        "dir(tokenizer)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_keras_api_names',\n",
              " '_keras_api_names_v1',\n",
              " 'char_level',\n",
              " 'document_count',\n",
              " 'filters',\n",
              " 'fit_on_sequences',\n",
              " 'fit_on_texts',\n",
              " 'get_config',\n",
              " 'index_docs',\n",
              " 'index_word',\n",
              " 'lower',\n",
              " 'num_words',\n",
              " 'oov_token',\n",
              " 'sequences_to_matrix',\n",
              " 'sequences_to_texts',\n",
              " 'sequences_to_texts_generator',\n",
              " 'split',\n",
              " 'texts_to_matrix',\n",
              " 'texts_to_sequences',\n",
              " 'texts_to_sequences_generator',\n",
              " 'to_json',\n",
              " 'word_counts',\n",
              " 'word_docs',\n",
              " 'word_index']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6qK_DckZcSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c85a2467-4924-4fa0-b53b-4951cdedeb97"
      },
      "source": [
        "print(\"Number of text sequence:\", tokenizer.document_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text sequence: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0IfRXJ1ZcS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "352fb1cb-e20e-4900-8b7c-38113f8bba52"
      },
      "source": [
        "# প্রতিটা শব্দ এবং তার বিপরীতে ইউনিক সংখ্যা \n",
        "tokenizer.index_word"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'অন্যতম',\n",
              " 2: 'হুমায়ূন',\n",
              " 3: 'আহমেদ',\n",
              " 4: 'ছিলেন',\n",
              " 5: 'একজন',\n",
              " 6: 'বাংলাদেশী',\n",
              " 7: 'ঔপন্যাসিক',\n",
              " 8: 'তিনি',\n",
              " 9: 'বিংশ',\n",
              " 10: 'শতাব্দীর',\n",
              " 11: 'জনপ্রিয়',\n",
              " 12: 'বাঙালি',\n",
              " 13: 'কথাসাহিত্যিকদের',\n",
              " 14: 'মধ্যে',\n",
              " 15: 'তাকে',\n",
              " 16: 'বাংলাদেশের',\n",
              " 17: 'স্বাধীনতা',\n",
              " 18: 'পরবর্তী',\n",
              " 19: 'শ্রেষ্ঠ',\n",
              " 20: 'লেখক',\n",
              " 21: 'বলে',\n",
              " 22: 'গণ্য',\n",
              " 23: 'করা',\n",
              " 24: 'হয়'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6AYKxOhZcS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "c3b48607-060d-4beb-eed6-4c2e369991f3"
      },
      "source": [
        "# উপরের টার উল্টা ম্যাপিং \n",
        "tokenizer.word_index"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'অন্যতম': 1,\n",
              " 'আহমেদ': 3,\n",
              " 'একজন': 5,\n",
              " 'ঔপন্যাসিক': 7,\n",
              " 'কথাসাহিত্যিকদের': 13,\n",
              " 'করা': 23,\n",
              " 'গণ্য': 22,\n",
              " 'ছিলেন': 4,\n",
              " 'জনপ্রিয়': 11,\n",
              " 'তাকে': 15,\n",
              " 'তিনি': 8,\n",
              " 'পরবর্তী': 18,\n",
              " 'বলে': 21,\n",
              " 'বাংলাদেশী': 6,\n",
              " 'বাংলাদেশের': 16,\n",
              " 'বাঙালি': 12,\n",
              " 'বিংশ': 9,\n",
              " 'মধ্যে': 14,\n",
              " 'লেখক': 20,\n",
              " 'শতাব্দীর': 10,\n",
              " 'শ্রেষ্ঠ': 19,\n",
              " 'স্বাধীনতা': 17,\n",
              " 'হয়': 24,\n",
              " 'হুমায়ূন': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJOesCXZcTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e1b8410-ceb9-40aa-f95c-9966f1afd402"
      },
      "source": [
        "# কতগুলো ইউনিক শব্দ আছে এবং সেই শব্দগুলো কতবার করে আছে সেটা দেখি \n",
        "print(\"Words counds:\", tokenizer.word_counts)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words counds: OrderedDict([('হুমায়ূন', 1), ('আহমেদ', 1), ('ছিলেন', 1), ('একজন', 1), ('বাংলাদেশী', 1), ('ঔপন্যাসিক', 1), ('তিনি', 1), ('বিংশ', 1), ('শতাব্দীর', 1), ('জনপ্রিয়', 1), ('বাঙালি', 1), ('কথাসাহিত্যিকদের', 1), ('মধ্যে', 1), ('অন্যতম', 2), ('তাকে', 1), ('বাংলাদেশের', 1), ('স্বাধীনতা', 1), ('পরবর্তী', 1), ('শ্রেষ্ঠ', 1), ('লেখক', 1), ('বলে', 1), ('গণ্য', 1), ('করা', 1), ('হয়', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW6_K3-FZcTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "961052a7-a7db-4ec7-a2c1-d44dc27081a7"
      },
      "source": [
        "print(\"Words docs:\", tokenizer.word_docs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words docs: defaultdict(<class 'int'>, {'বাংলাদেশী': 1, 'হুমায়ূন': 1, 'আহমেদ': 1, 'ঔপন্যাসিক': 1, 'একজন': 1, 'ছিলেন': 1, 'অন্যতম': 2, 'জনপ্রিয়': 1, 'কথাসাহিত্যিকদের': 1, 'তিনি': 1, 'বাঙালি': 1, 'শতাব্দীর': 1, 'মধ্যে': 1, 'বিংশ': 1, 'শ্রেষ্ঠ': 1, 'তাকে': 1, 'স্বাধীনতা': 1, 'পরবর্তী': 1, 'করা': 1, 'হয়': 1, 'বলে': 1, 'গণ্য': 1, 'লেখক': 1, 'বাংলাদেশের': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP30jmjLZcTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a32a2a9f-c2c2-4743-de2c-2f39a47cd4ec"
      },
      "source": [
        "# লিস্ট আকারে ইনপুট দিতে হবে । \n",
        "sequence = tokenizer.texts_to_sequences([\n",
        "    \"হুমায়ূন আহমেদ ছিলেন একজন বাংলাদেশী ঔপন্যাসিক\",\n",
        "    \"তিনি বিংশ শতাব্দীর জনপ্রিয় বাঙালি কথাসাহিত্যিকদের মধ্যে অন্যতম\"])\n",
        "print('Sequence:', sequence)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [[2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzPz4ZxTZcTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "688bd3a4-9c5f-41df-b390-b0fddd5055c2"
      },
      "source": [
        "# সিকুয়েন্স থেকে টেক্সট এ ফিরে আশা । \n",
        "_texts = tokenizer.sequences_to_texts(\n",
        "    [[2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 1]]\n",
        ")\n",
        "print(\"Texts:\", _texts)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texts: ['হুমায়ূন আহমেদ ছিলেন একজন বাংলাদেশী ঔপন্যাসিক', 'তিনি বিংশ শতাব্দীর জনপ্রিয় বাঙালি কথাসাহিত্যিকদের মধ্যে অন্যতম']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUBLF_VWZcT5",
        "colab_type": "text"
      },
      "source": [
        "আমরা চাইলে এই টোকেনাইজার কে সেভ করে রাখতে পারি । যাতে পরে দরকার হলে এটা কে লোড করে কাজ করা যায় । \n",
        "সেভ করে রাখার সুবিধা হল পরে চাইলে খুব সহজেই ব্যবহার করতে পারব । এবং আমাদের কে `fit_on_texts` ব্যবহার করে\n",
        "ইনিসিয়ালাইজ করতে হবে না । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdL1hzpRZcT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "# এই ফাইলে আমরা আমাদের টোকেনাইজার কে সেভ করে রাখব \n",
        "path_to_tokenizer_file = 'tokenizer.json'\n",
        "# টোকেনাইজার কে জেসন এ কনভার্ট করি \n",
        "bangla_tokenizer_json = tokenizer.to_json()\n",
        "\n",
        "# ফাইল এ রাইট করে ফেলি\n",
        "with open(path_to_tokenizer_file, 'w', encoding='utf8') as fp:\n",
        "    fp.write(json.dumps(bangla_tokenizer_json, ensure_ascii=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IE_vkIeZcUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# আমরা নিশ্চিত হওয়ার জন্য আগের কে ডিলিট করে দেই  \n",
        "del tokenizer\n",
        "\n",
        "# এখন আমরা আমাদের সেভ করা কে লোড করি \n",
        "with open(path_to_tokenizer_file, 'r', encoding='utf8') as fp:\n",
        "    tokenizer_json_object = json.load(fp)\n",
        "    tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(\n",
        "                    tokenizer_json_object\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7c5P8_GZcUP",
        "colab_type": "text"
      },
      "source": [
        "এখন দেখি আমাদের নতুন লোড করা আগের মতই কাজ করে কি না । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvTzJPggZcUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4560d180-60ea-4a47-f1ea-7454c59a320a"
      },
      "source": [
        "# লিস্ট আকারে ইনপুট দিতে হবে । \n",
        "sequence = tokenizer.texts_to_sequences([\n",
        "    \"হুমায়ূন আহমেদ ছিলেন একজন বাংলাদেশী ঔপন্যাসিক\",\n",
        "    \"তিনি বিংশ শতাব্দীর জনপ্রিয় বাঙালি কথাসাহিত্যিকদের মধ্যে অন্যতম\"])\n",
        "print('Sequence:', sequence)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [[2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuceadbmZcUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "923dbb6f-b99a-441d-9579-0169422d6e71"
      },
      "source": [
        "# সিকুয়েন্স থেকে টেক্সট এ ফিরে আশা । \n",
        "_texts = tokenizer.sequences_to_texts(\n",
        "    [[2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 1]]\n",
        ")\n",
        "print(\"Texts:\", _texts)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texts: ['হুমায়ূন আহমেদ ছিলেন একজন বাংলাদেশী ঔপন্যাসিক', 'তিনি বিংশ শতাব্দীর জনপ্রিয় বাঙালি কথাসাহিত্যিকদের মধ্যে অন্যতম']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-igq5uGjZcUm",
        "colab_type": "text"
      },
      "source": [
        "আমরা দেখতে পাচ্ছি যে এটা আগের মতই কাজ করতেছে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSK5J2U0ZcUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
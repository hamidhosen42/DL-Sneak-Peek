{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# লিনিয়ার রিগ্রেসন\n",
    "\n",
    "**সমস্যা - ১**\n",
    "মনে করেন একটা বাড়ি সম্পর্কে আপনাকে বিভিন্ন ইনফরমেশন দেয়া আছে । এখন আপনাকে এই বাড়ির ইনফরমেশন বিশ্লেষণ করে বাড়ির দাম কত হবে সেটা বলে দিতে হবে । \n",
    "\n",
    "**সমস্যা - ২**\n",
    "মনে করেন আপানকে কোন একটা কোম্পানির একজন ইমপ্লয়ি সম্পর্কে বিভিন্ন ইনফরমেশন দেয়া আছে । এখন এই ইনফরমেশন বিশ্লেষণ করে করে আপনাকে বলতে হবে এই ইমপ্লয়ির বেতন কত হতে পারে । \n",
    "\n",
    "এই দুইটা সমস্যার মাঝেই একটা কমন বিষয় আছে । কমন বিষয়টা কি সেটা কি ধরতে পারছেন ? দুই ক্ষেত্রেই আপানকে একটা সংখ্যা (বাড়ির দাম, বেতন) প্রেডিক্ট করতে হচ্ছে । যে ধরনের সমস্যায় আপনাকে একটা সংখ্যা প্রেডিক্ট করতে বলা হবে সেই সমস্যা গুলোকে মেশিন লার্নিং এর ভাষায় রিগ্রেসন প্রবলেম বলে । \n",
    "\n",
    "**তাহলে লিনিয়ার রিগ্রেসন কি ?**\n",
    "\n",
    "লিনিয়ার রিগ্রেসন হল এমন ধরনের রিগ্রেসন সমস্যা যেটা কোন একটা লিনিয়ার সমীকরণ ব্যাবহারে করে সমাধান করা যায় । "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এই নোটবুকে আমরা গ্র্যাডিয়েন্ট-টেপ ব্যাবহার করে লিনিয়ার রিগ্রেসনের একটা সমস্যা সমাধান করার চেষ্টা করব । \n",
    "\n",
    "**সমস্যা**\n",
    "\n",
    "মনে করেন আমাদেরকে যদি ইনপুট দেয়া হয় এই রকম,\n",
    "\n",
    "`x = [0, 1, 2, 3, 4]`\n",
    "\n",
    "তাহলে অউটপুট দিতে হবে এই রকম, \n",
    "\n",
    "`y = [5, 15, 25, 35]`\n",
    "\n",
    "অর্থাৎ ০ হলে ৫, ১ হলে ১৫, ২ হলে ২৫, ৪ হলে ৩৫ । আপনারা কি বলতে পরবেন এই সংখ্যাটা কিভাবে আসতেছে ? একটু চিন্তা করে দেখেন পারেন কি না । এটা আসলে `y = 10x+5` এই সূত্র দিয়ে আসতেছে । আপনি x এর মান ০, ১, ২ ... বসে দেখেন । আমরা যদি নরমাল প্রোগ্রামিং চিন্তা করি তাহলে সরাসরি এই সূত্র ব্যাবহার করে আমরা অউটপুট পেতে পারি । কিন্তু এখানে আমরা দেখব মেশিন লার্নিং ব্যাবহার করে কিভাবে এই সমস্যা সমাধান করা যায় । \n",
    "\n",
    "আপনারা যদি সমীকরণটা একটু ভালভাবে খেয়াল করেন তাহলে দেখতে পারবেন এটা একটা লিনিয়া সমীকরণ । মনে করেন আমরা সমীকরণে ১০ এবং ৫ এই দুইটা মান জানি না । ধরে নিলাম দুইটা মান a, এবং b তাহলে সমীকরণ টা এই রকম হবে `y = ax+b` এখানে আমরা x এর মানটা কি সেটা জানি । এখন আমাদের কে এমন একটা প্রোগ্রাম লিখতে হবে যেটা আমাদের কে a, b এর মান বের করে দিবে । এবং এই প্রোগ্রাম যদি আমাদেরকে a, b এর মান যথাক্রমে 10, 5 নিয়ে এসে দিতে পারে তাহলে আমরা বলতে পারি আমরা আমাদের সমস্যা সমাধান করতে পেরেছি । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "x_train = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "# Target\n",
    "y_train = np.array([5,15,25,35,45,55,65,75,85,95,105]) # y = 10x+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "শুরুতে আমরা a, b এর একটা random মান ধরে নেই । এই দুইটা ভেরিয়েবল কে আমরা ধীরে ধীরে ১০, ৫ এর কাছাকাছি নিয়ে যাওয়ার চেষ্টা করব । যেহেতু এই ভেরিয়েবল গুলো মেশিন লার্নিং মডেল ট্রেনিং করার সময় আপডেট হয় এইজন্য এই ধরনের ভেরিয়েবল কে মেশিন লার্নিং এর ভাষায় ট্রেইনেবল ভেরিয়েবল বলে\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 0.23271672  b: 0.5607032\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(random.random())\n",
    "b = tf.Variable(random.random())\n",
    "\n",
    "print('a:', a.numpy(), ' b:', b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এখন আমাদের এমন একটা ফাংশন দরকার যেটা আমরা যখন a, b এর মান কম বেশি করব তখন বলে দিবে আমরা আমদের টার্গেট থেকে কত দুরে বা কাছে । মেশিন লার্নিং এর ভাষায় এই ধরনের ফাংশনে কে বলে লস ফাংশন বা কস্ট ফাংশন । অর্থাৎ লস যদি আমাদের বেশি হয় তাহলে বুঝতে হবে আমরা আমাদের টার্গেট থেকে অনেক দুরে আছি । লস যদি কম হয় তাহলে বুঝতে হবে আমারা আমাদের টার্গেটের কাছা কাছি আছি । লস শূন্য মানে আমাদের যেটা টার্গেট আমরা ঠিক সেটাই পেয়ে গেছি । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss(real_y, pred_y):\n",
    "    return tf.abs(real_y - pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এখন আমাদের দরকার একটা ট্রেনিং লুপ ফাংশন সেটা টার প্রত্যেক ইটারেশনে / ইপকে আমাদের ট্রেইনেবল ভেরিয়েবল a, b কে আপডেট করবে । a, b আপডেট করার সূত্র হল এই রকম\n",
    "```python\n",
    "a = a - gradient_of_a * learning_rate\n",
    "b = b - gradient_of_b * learning_rate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=0 y ≈ 0.288x + 0.572\n",
      "epochs=100 y ≈ 5.788x + 1.672\n",
      "epochs=200 y ≈ 10.332x + 2.666\n",
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=300 y ≈ 10.264x + 3.142\n",
      "epochs=400 y ≈ 10.196x + 3.618\n",
      "epochs=500 y ≈ 10.128x + 4.094\n",
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=600 y ≈ 10.058x + 4.568\n",
      "epochs=700 y ≈ 10.008x + 4.914\n",
      "epochs=800 y ≈ 9.994x + 4.990\n",
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=900 y ≈ 9.994x + 4.990\n",
      "epochs=1000 y ≈ 9.994x + 4.990\n",
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=1439 y ≈ 10.049x + 5.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=1752 y ≈ 9.994x + 4.990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=1999 y ≈ 10.049x + 5.001\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001 # Learning reate\n",
    "losses = [] # for tracking loss value\n",
    "\n",
    "def step(real_x, real_y, e):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Make prediction\n",
    "        pred_y = a * real_x + b\n",
    "        # Calculate loss\n",
    "        reg_loss = loss(real_y, pred_y)\n",
    "        losses.append(tf.reduce_sum(reg_loss))\n",
    "    # Calculate gradients\n",
    "    a_gradients, b_gradients = tape.gradient(reg_loss, (a, b))\n",
    "\n",
    "    # Update variables\n",
    "    a.assign_sub(a_gradients * lr)\n",
    "    b.assign_sub(b_gradients * lr)\n",
    "    print(f'epochs={e} y ≈ {a.numpy():.3f}x + {b.numpy():.3f}') \n",
    "\n",
    "EPOCHS = 2000\n",
    "for e in range(EPOCHS):\n",
    "    step(x_train, y_train, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`step` ফাংশনে আমরা `tape.gradient(reg_loss, (a, b))` ব্যাবহারে করেছি । এখানে `reg_loss` দেয়ার করন হল আমাদের এই লসের সমীকরণ কেই অপটিমাইজ করতে হবে । a, b এর এমন মান বের করতে হবে যাতে করে লস এর মান সবচেয়ে কম হয় । \n",
    "\n",
    "২০০০ ইপক পরে আমাদের a, b এর মান এসেছে 10.049, 5.001 যেটা ১০, এবং ৫ এর খুব কাছাকাছি । এখন আমরা যদি লস এবং ইপক প্লট করে দেখি তাহলে নিচের মত দেখতে পাব । এখানে থেকে বোঝা যাচ্ছে যে ইপক যাওয়ার সাথে সাথে লস ধীরে ধীরে কমে আসছে । "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ep = list(range(EPOCHS))\n",
    "plt.plot(ep, losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/tf-gradienttape-explained-for-keras-users-cc3f06276f22"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.x] *",
   "language": "python",
   "name": "conda-env-tf2.x-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
